numHiddenUnits = 100;
numClasses=9;
numFeatures = 2;
layers = [ ...
    sequenceInputLayer(numFeatures)
    lstmLayer(numHiddenUnits,'OutputMode','last')
    fullyConnectedLayer(numClasses)
    softmaxLayer
    classificationLayer];
maxEpochs = 400;
miniBatchSize =10 ;%128 default
options = trainingOptions('adam', ...
    'ExecutionEnvironment','cpu', ...
    'MaxEpochs',maxEpochs, ...
    'MiniBatchSize',miniBatchSize, ...
    'GradientThreshold',1, ...
    'InitialLearnRate',0.005, ...
    'LearnRateSchedule','piecewise', ...
    'LearnRateDropPeriod',120, ...
    'LearnRateDropFactor',0.2, ...
    'Verbose',0, ...
    'Plots','training-progress');
net = trainNetwork(input_features, Y_train,layers,options);
%%
L = size(T_on);
for i = 1:9%L(1,1) % 120
    for j =1 :29 % 24 
        Y_train(j+24*(i-1),1) =categorical(i);
        first(j+24*(i-1),1) =i;
        X_train{j+24*(i-1),1} = data_trial_grip_close{i}{j}(:,2).';%T_24(i,:);
    end 
end % create response 
%%
L = size(T_24);
for i = 1:L(1,1)
    X_train{i,1} = T_24(i,:);
end  % create training input 
%%
table = table([T_24], Line);
